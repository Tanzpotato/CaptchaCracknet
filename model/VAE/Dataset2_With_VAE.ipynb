{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6121992,"sourceType":"datasetVersion","datasetId":3491375},{"sourceId":7263712,"sourceType":"datasetVersion","datasetId":3991186},{"sourceId":240007604,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image\nfrom torch.utils import data\nfrom torch.utils.data import random_split,DataLoader\nimport string\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nimport shutil\nfrom torchvision import datasets, transforms\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:05.256666Z","iopub.execute_input":"2025-05-21T17:39:05.256859Z","iopub.status.idle":"2025-05-21T17:39:12.913027Z","shell.execute_reply.started":"2025-05-21T17:39:05.256834Z","shell.execute_reply":"2025-05-21T17:39:12.912308Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"USE_CUDA = torch.cuda.is_available()\n\nprint(\"Device : {0}\".format(\"GPU\" if USE_CUDA else \"CPU\"))\ndevice = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\ncpu_device = torch.device(\"cpu\")\n\nBATCH_SIZE=128\nVAL_SPLIT=0.2\n\nAFFN_KERNEL=5\nAFFN_STRIDE=1\nAFFN_DEPTH=2\nLATENT_DIM=256\nENCODER_SHAPE=16*56*184\n\nCRNN_KERNEL=5\nCRNN_POOL_KERNEL=2\nCRNN_DROPOUT=0.3\nCRNN_LATENT=128\nLSTM_HIDDEN_DIM=32\nVOCAB_SIZE=26+10\nOUTPUT_LENGTH=6\n\nSAVE_EPOCH=10\nVAL_EPOCH=1\nEPOCHS=40\nepoch_count = [i for i in range(1,EPOCHS+1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:12.914667Z","iopub.execute_input":"2025-05-21T17:39:12.914935Z","iopub.status.idle":"2025-05-21T17:39:13.001862Z","shell.execute_reply.started":"2025-05-21T17:39:12.914918Z","shell.execute_reply":"2025-05-21T17:39:13.001163Z"}},"outputs":[{"name":"stdout","text":"Device : GPU\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(\"CUDA is available. Using GPU(s):\", torch.cuda.device_count())\nelse:\n    device = torch.device('cpu')\n    print(\"CUDA is not available. Using CPU.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:13.002605Z","iopub.execute_input":"2025-05-21T17:39:13.002823Z","iopub.status.idle":"2025-05-21T17:39:13.197469Z","shell.execute_reply.started":"2025-05-21T17:39:13.002799Z","shell.execute_reply":"2025-05-21T17:39:13.196901Z"}},"outputs":[{"name":"stdout","text":"CUDA is available. Using GPU(s): 2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data = '/kaggle/input/captchaimgdata/trainset'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:13.198155Z","iopub.execute_input":"2025-05-21T17:39:13.198450Z","iopub.status.idle":"2025-05-21T17:39:13.202150Z","shell.execute_reply.started":"2025-05-21T17:39:13.198432Z","shell.execute_reply":"2025-05-21T17:39:13.201470Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, random_split, Dataset\nimport string\nimport zipfile\n\ndef get_dataloaders(data_dir, batch_size=64, val_split=0.2, shuffle=True, num_workers=0):\n    #torch.manual_seed(42)\n    #torch.cuda.manual_seed(42)\n    # Define the character set (vocabulary)\n    characters = string.ascii_uppercase + string.digits  # Uppercase + lowercase + digits\n    char_to_idx = {char: idx for idx, char in enumerate(characters)}\n    vocab_size = len(characters)\n\n    class CustomDataset(Dataset):\n        def __init__(self, root_dir, transform=None):\n            self.root_dir = root_dir\n            self.transform = transform\n            self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n            self.labels = [os.path.basename(f).split('.')[0].upper() for f in self.image_paths]  # Extract filename as label\n\n        def __len__(self):\n            return len(self.image_paths)\n\n        def __getitem__(self, idx):\n            img_path = self.image_paths[idx]\n            image = Image.open(img_path).convert('RGB')\n            label_str = self.labels[idx]\n\n            # Convert label string to one-hot encoded tensor\n            label_indices = [char_to_idx[c] for c in label_str if c in char_to_idx]  # Map characters to indices\n            label_tensor = torch.zeros(len(label_indices),dtype=torch.long)  # One-hot encoding tensor\n            for i, index in enumerate(label_indices):\n                label_tensor[i] = index  # Set one-hot encoding\n\n            if self.transform:\n                image = self.transform(image)\n\n            return image, label_tensor\n\n    transform = transforms.Compose([\n        transforms.Resize((64,192)),  # Resize to a fixed size\n        transforms.ToTensor(),\n        transforms.Grayscale(),\n        transforms.Lambda(lambda x: x / 255),\n    ])\n\n    dataset = CustomDataset(root_dir=data_dir, transform=transform)\n    print(f\"Dataset size: {len(dataset)}\")  # Print dataset size\n\n    # Compute train-validation split\n    total_size = len(dataset)\n    val_size = int(total_size * val_split)\n    train_size = total_size - val_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_loader, val_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:13.203967Z","iopub.execute_input":"2025-05-21T17:39:13.204695Z","iopub.status.idle":"2025-05-21T17:39:13.216435Z","shell.execute_reply.started":"2025-05-21T17:39:13.204679Z","shell.execute_reply":"2025-05-21T17:39:13.215878Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_loader,val_loader=get_dataloaders(data_dir= data, batch_size=BATCH_SIZE, val_split=0.2, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:13.217145Z","iopub.execute_input":"2025-05-21T17:39:13.217304Z","iopub.status.idle":"2025-05-21T17:39:13.551478Z","shell.execute_reply.started":"2025-05-21T17:39:13.217291Z","shell.execute_reply":"2025-05-21T17:39:13.550776Z"}},"outputs":[{"name":"stdout","text":"Dataset size: 26155\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_features_batch, train_labels_batch = next(iter(train_loader))\ntrain_features_batch.shape, train_labels_batch.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:13.552243Z","iopub.execute_input":"2025-05-21T17:39:13.552458Z","iopub.status.idle":"2025-05-21T17:39:14.728535Z","shell.execute_reply.started":"2025-05-21T17:39:13.552435Z","shell.execute_reply":"2025-05-21T17:39:14.727993Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(torch.Size([128, 1, 64, 192]), torch.Size([128, 6]))"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n            y_true = y_true.cpu()  \n            y_pred = y_pred.cpu()\n\n            y_true = y_true.view(-1)  \n            y_pred = y_pred.view(-1)  \n\n            correct = torch.eq(y_true, y_pred).sum().item()\n            total_samples = len(y_true) \n\n            acc = (correct / total_samples)*100\n            return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.729183Z","iopub.execute_input":"2025-05-21T17:39:14.729377Z","iopub.status.idle":"2025-05-21T17:39:14.733775Z","shell.execute_reply.started":"2025-05-21T17:39:14.729353Z","shell.execute_reply":"2025-05-21T17:39:14.733212Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Encoder(nn.Sequential):\n    def __init__(self,n,kernel_size,stride):\n        super().__init__(\n            nn.Conv2d(in_channels=4**(n-1),out_channels=4**n,kernel_size=kernel_size,stride=stride),\n            nn.BatchNorm2d(num_features=4**n),\n            nn.ReLU(inplace=False)\n        )\n\nclass Decoder(nn.Sequential):\n    def __init__(self,n,kernel_size,stride):\n        super().__init__(\n            nn.ConvTranspose2d(in_channels=4**n,out_channels=4**(n-1),kernel_size=kernel_size,stride=stride),\n            nn.BatchNorm2d(num_features=4**(n-1)),\n            nn.ReLU(inplace=False)\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.734522Z","iopub.execute_input":"2025-05-21T17:39:14.734750Z","iopub.status.idle":"2025-05-21T17:39:14.748323Z","shell.execute_reply.started":"2025-05-21T17:39:14.734724Z","shell.execute_reply":"2025-05-21T17:39:14.747599Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, n, latent_dim,encoder_shape):\n        super(VAE, self).__init__()\n        self.latent_dim = latent_dim\n        self.n = n\n        self.alpha = nn.Parameter(torch.randn(n - 1)).to(device)\n        self.encoders = []\n        for i in range(1, n + 1):\n            self.encoders.append(Encoder(i, AFFN_KERNEL, AFFN_STRIDE).to(device))\n        self.decoders = []\n        for i in range(n, 0, -1):\n            self.decoders.append(Decoder(i, AFFN_KERNEL, AFFN_STRIDE).to(device))\n        self.fc_mu = nn.LazyLinear(latent_dim)\n        self.fc_logvar = nn.LazyLinear(latent_dim)\n        self.flat_layer = nn.Flatten(1,3)\n        #ENCODER_SHAPE=16*56*184\n        self.linear = nn.Linear(latent_dim,encoder_shape)\n    def parameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, x):\n        residuals = []\n        for i, enc in enumerate(self.encoders):\n            x = enc(x)\n            if i < self.n - 1:\n                x= x * (1 - self.alpha[i])\n                residuals.append(x * self.alpha[i])\n    \n        batch,a,b,c=x.shape\n        x= self.flat_layer(x)\n        mu = self.fc_mu(x)\n        logvar = self.fc_logvar(x)\n        z = self.parameterize(mu, logvar)\n        z = self.linear(z)\n        unflatten = torch.nn.Unflatten(1,(a,b,c))\n        x = unflatten(z)\n        for i, dec in enumerate(self.decoders):\n            x = dec(x)\n            if i < self.n - 1:           \n                x = x + residuals.pop() \n        return x, mu, logvar\n        \ndef loss_function(reconstructed_x, y, mu, logvar):\n    reconstruction_loss = nn.functional.binary_cross_entropy(reconstructed_x, y, reduction='sum')\n    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return reconstruction_loss + kl_div","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.749096Z","iopub.execute_input":"2025-05-21T17:39:14.749353Z","iopub.status.idle":"2025-05-21T17:39:14.763531Z","shell.execute_reply.started":"2025-05-21T17:39:14.749331Z","shell.execute_reply":"2025-05-21T17:39:14.762833Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CRNN(nn.Module):\n    def __init__(self, in_channels, kernel_size, pool_kernel_size, dropout, latent_dim, lstm_hidden_dim, vocab_size, output_length=5):\n        super().__init__()\n        self.lstm_hidden_dim = lstm_hidden_dim\n        self.output_length = output_length  \n        self.vocab_size = vocab_size\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=in_channels*2, kernel_size=kernel_size, padding=2),\n            nn.BatchNorm2d(num_features=in_channels*2),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=pool_kernel_size)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels*2, out_channels=in_channels*4, kernel_size=kernel_size, padding=2),\n            nn.BatchNorm2d(num_features=in_channels*4),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=pool_kernel_size)\n        )\n        self.flatten = nn.Flatten()\n        self.dropout = nn.Dropout(dropout)\n        self.latent_fc = nn.LazyLinear(latent_dim)\n        self.lstm = nn.LSTM(input_size=latent_dim, hidden_size=lstm_hidden_dim, num_layers=1, batch_first=True)\n        self.output_fc = nn.Linear(lstm_hidden_dim, vocab_size)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n\n        conv1_out = self.conv1(x)\n        conv2_out = self.conv2(conv1_out)\n        flattened = self.flatten(conv2_out)\n        dropped = self.dropout(flattened)\n        latent = self.latent_fc(dropped)\n\n        lstm_input = latent.unsqueeze(1)\n\n        h0 = torch.zeros(1, batch_size, self.lstm_hidden_dim, device=x.device)\n        c0 = torch.zeros(1, batch_size, self.lstm_hidden_dim, device=x.device)\n\n        outputs = []\n\n        for _ in range(self.output_length):\n            out, (h0, c0) = self.lstm(lstm_input, (h0, c0))  # out shape: (batch_size, 1, lstm_hidden_dim)\n\n            logits = self.output_fc(out.squeeze(1))  # Shape: (batch_size, vocab_size)\n\n            outputs.append(logits)\n\n        outputs = torch.stack(outputs, dim=1)  # Shape: (batch_size, 6, vocab_size)\n\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.764259Z","iopub.execute_input":"2025-05-21T17:39:14.764584Z","iopub.status.idle":"2025-05-21T17:39:14.776911Z","shell.execute_reply.started":"2025-05-21T17:39:14.764563Z","shell.execute_reply":"2025-05-21T17:39:14.776412Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class CaptchaCrackNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.VAE = VAE(AFFN_DEPTH,LATENT_DIM,ENCODER_SHAPE).to(device)\n\n        self.conv1=nn.Sequential(\n            nn.Conv2d(in_channels=1,out_channels=32,kernel_size=5,padding=2),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=2)\n        )\n\n        self.conv2=nn.Sequential(\n                    nn.Conv2d(in_channels=32,out_channels=48,kernel_size=5,padding=2),\n                    nn.ReLU(inplace=False),\n                    nn.MaxPool2d(kernel_size=2)\n                )\n\n        self.conv3=nn.Sequential(\n            nn.Conv2d(in_channels=48,out_channels=64,kernel_size=5,padding=2),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=2)\n        )\n\n        self.res=nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=2, padding=2)\n\n        self.crnn=CRNN(64,CRNN_KERNEL,CRNN_POOL_KERNEL,CRNN_DROPOUT,CRNN_LATENT,LSTM_HIDDEN_DIM,VOCAB_SIZE,OUTPUT_LENGTH).to(device)\n\n    def forward(self,x):\n        out,mu,logvar=self.VAE(x)\n        res_out=self.res(x)\n        conv1_out=self.conv1(out)\n        conv2_out=self.conv2(conv1_out+res_out)\n        conv3_out=self.conv3(conv2_out)\n        output=self.crnn(conv3_out)\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.777743Z","iopub.execute_input":"2025-05-21T17:39:14.777968Z","iopub.status.idle":"2025-05-21T17:39:14.793229Z","shell.execute_reply.started":"2025-05-21T17:39:14.777944Z","shell.execute_reply":"2025-05-21T17:39:14.792578Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train(model,train_loader,val_loader,epochs=EPOCHS):\n    #torch.manual_seed(42)\n    #torch.cuda.manual_seed(42)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n    model.to(device)\n    train_history=[]\n    val_history=[]\n    train_acc=[]\n    val_acc=[]\n    for epoch in range(1,epochs+1):\n        print(f\"Epoch {epoch}:\")\n        avg_acc=0\n        avg_loss=0\n        model.train()\n        for batch_num,(X,y) in enumerate(tqdm(train_loader,desc=\"Progress: \")):\n\n            X=X.to(device)\n            y=y.to(device)\n            optimizer.zero_grad()\n            preds=model(X)\n\n            loss=loss_fn(preds.view(-1, VOCAB_SIZE),y.view(-1))\n            loss.backward()\n            optimizer.step()\n\n            avg_loss+=loss.item()\n            avg_acc+=accuracy_fn(y_true=y.cpu(),y_pred=torch.argmax(preds,dim=2).cpu())\n\n\n        avg_loss/=len(train_loader)\n        avg_acc/=len(train_loader)\n        train_acc.append(avg_acc)\n        print(f\"Train Acc: {avg_acc}%\")\n        train_history.append(avg_loss)\n        print(f\"Train Loss: {avg_loss}\")\n\n        eval_loss=0\n        eval_acc=0\n        if VAL_EPOCH and epoch%VAL_EPOCH==0:\n            model.eval()\n            with torch.no_grad():\n                for batch_num,(X,y) in enumerate(tqdm(val_loader,desc=\"Progress: \")):\n                    X=X.to(device)\n                    y=y.to(device)\n                    preds=model(X)\n                    loss=loss_fn(preds.view(-1, VOCAB_SIZE),y.view(-1))\n                    eval_acc+=accuracy_fn(y_true=y,y_pred=torch.argmax(preds,dim=2))\n                    eval_loss+=loss.item()\n                eval_acc/=len(val_loader)\n                val_acc.append(eval_acc)\n                print(f\"Val Acc: {eval_acc}%\")\n                eval_loss/=len(val_loader)\n                val_history.append(eval_loss)\n                print(f\"Val Loss: {eval_loss}\")\n\n\n        if SAVE_EPOCH and epoch%SAVE_EPOCH==0:\n            print(\"Saving model\")\n            path=str(epoch)+'.pth'\n            torch.save(model.state_dict(), path)\n    torch.save(model.state_dict(),'final.pth')\n\n    return train_history,val_history,train_acc,val_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.793952Z","iopub.execute_input":"2025-05-21T17:39:14.794166Z","iopub.status.idle":"2025-05-21T17:39:14.807369Z","shell.execute_reply.started":"2025-05-21T17:39:14.794152Z","shell.execute_reply":"2025-05-21T17:39:14.806791Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model=CaptchaCrackNet().to(device)\n\ntrain_history,val_history,train_acc,val_acc =train(model,train_loader,val_loader,EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:14.809923Z","iopub.execute_input":"2025-05-21T17:39:14.810158Z","iopub.status.idle":"2025-05-21T17:39:32.750410Z","shell.execute_reply.started":"2025-05-21T17:39:14.810143Z","shell.execute_reply":"2025-05-21T17:39:32.749285Z"}},"outputs":[{"name":"stdout","text":"Epoch 1:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Progress:   0%|          | 0/164 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5959838c03014c9b81990596f779ccd8"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2918421517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCaptchaCrackNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/3110486508.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3219045208.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mres_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mconv1_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/1727589717.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_logvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1770\u001b[0m                 ):\n\u001b[1;32m   1771\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks_with_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1772\u001b[0;31m                         \u001b[0margs_kwargs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1773\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0margs_kwargs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_kwargs_result\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/lazy.py\u001b[0m in \u001b[0;36m_infer_parameters\u001b[0;34m(self, module, args, kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[1;32m    273\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_uninitialized_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'module {self._get_name()} has not been fully initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36minitialize_parameters\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaterialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaterialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36mmaterialize\u001b[0;34m(self, shape, device, dtype)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_to_become\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.33 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.65 GiB is free. Process 2735 has 13.08 GiB memory in use. Of the allocated memory 12.92 GiB is allocated by PyTorch, and 36.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 6.33 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.65 GiB is free. Process 2735 has 13.08 GiB memory in use. Of the allocated memory 12.92 GiB is allocated by PyTorch, and 36.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"loaded_model = CaptchaCrackNet() \n\nstate_dict = torch.load('final.pth', map_location=torch.device('cpu')) \n\nloaded_model.load_state_dict(state_dict) \n\nloaded_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.750763Z","iopub.status.idle":"2025-05-21T17:39:32.750985Z","shell.execute_reply.started":"2025-05-21T17:39:32.750881Z","shell.execute_reply":"2025-05-21T17:39:32.750892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_predictions(epochs,losses,predictions=None):\n  plt.figure(figsize=(5,4))\n  plt.plot(epochs, losses)\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.title('Train Accuracy vs. Epoch')\n  plt.show()\nplot_predictions(epoch_count,train_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.752183Z","iopub.status.idle":"2025-05-21T17:39:32.752483Z","shell.execute_reply.started":"2025-05-21T17:39:32.752312Z","shell.execute_reply":"2025-05-21T17:39:32.752326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"characters = string.ascii_uppercase + string.digits\nidx_to_char = {idx: char for idx, char in enumerate(characters)}\ndef to_text(arr):\n    ans=''\n    for c in arr:\n        ans=ans+idx_to_char[c.item()]\n    return ans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.754221Z","iopub.status.idle":"2025-05-21T17:39:32.754584Z","shell.execute_reply.started":"2025-05-21T17:39:32.754427Z","shell.execute_reply":"2025-05-21T17:39:32.754441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from itertools import groupby\n\ndef to_text(pred_tensor):\n    pred_indices = pred_tensor.cpu().numpy().tolist()\n    result = ''.join([idx_to_char[idx] for idx, _ in groupby(pred_indices) if idx != VOCAB_SIZE - 1])\n    return result\n\nimport matplotlib.pyplot as plt\n\nmodel.eval()  # Set to eval mode\n\nwith torch.no_grad():\n    for X, y in train_loader:\n        # Select one sample\n        X_single = X[0]\n        y_single = y[0]\n\n        # Show original image\n        plt.imshow(X_single.numpy().squeeze(), cmap='gray')\n        plt.title(\"Original CAPTCHA Image\")\n        plt.axis(\"off\")\n        plt.show()\n\n        # Model output\n        input_tensor = X_single.unsqueeze(0).to(device)\n        output = model(input_tensor)  # [W, B, VOCAB_SIZE]\n        output = F.log_softmax(output, dim=2)\n        pred = output.argmax(dim=2).squeeze(1)  # [W]\n\n        # Decode prediction\n        pred_text=''\n        for i in pred:\n            pred_text+= to_text(i)\n        true_text = ''.join([idx_to_char[c.item()] for c in y_single if c.item() != -1])\n\n        print(f\"True : {true_text}\")\n        print(f\"Pred : {pred_text}\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.755298Z","iopub.status.idle":"2025-05-21T17:39:32.755597Z","shell.execute_reply.started":"2025-05-21T17:39:32.755447Z","shell.execute_reply":"2025-05-21T17:39:32.755461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_predictions_and_labels(model, dataloader):\n    model.eval()\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Collecting predictions\"):\n            images = images.to(device)\n            outputs = model(images)\n            outputs = F.log_softmax(outputs, dim=2)\n            preds = outputs.argmax(dim=2).permute(1, 0)  # [B, W]\n\n            all_preds.extend(preds.cpu())\n            all_targets.extend(labels.cpu())\n\n    return all_preds, all_targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.756624Z","iopub.status.idle":"2025-05-21T17:39:32.756919Z","shell.execute_reply.started":"2025-05-21T17:39:32.756772Z","shell.execute_reply":"2025-05-21T17:39:32.756785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_preds, val_targets = get_predictions_and_labels(model, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.757856Z","iopub.status.idle":"2025-05-21T17:39:32.758178Z","shell.execute_reply.started":"2025-05-21T17:39:32.757995Z","shell.execute_reply":"2025-05-21T17:39:32.758008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = []\ntargets = []\nfor i in val_preds:\n    for j in i:\n        preds.append(j.item())\nfor i in val_targets:\n    for j in i:\n        targets.append(j.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.759297Z","iopub.status.idle":"2025-05-21T17:39:32.759581Z","shell.execute_reply.started":"2025-05-21T17:39:32.759436Z","shell.execute_reply":"2025-05-21T17:39:32.759449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy as np\ndef Confmatrix(y_pred,targets):\n    confmat = ConfusionMatrix(num_classes=VOCAB_SIZE, task='multiclass')\n    y_pred = torch.tensor(y_pred, dtype=torch.int64) \n    targets = torch.tensor(targets, dtype=torch.int64)\n    \n    confmat_tensor = confmat(preds=y_pred,target=targets) \n\n    fig, ax = plot_confusion_matrix(\n        conf_mat=confmat_tensor.cpu().numpy(), # Convert back to NumPy for plotting\n        class_names=list(characters), # turn the row and column labels into class names\n        figsize=(10, 7)\n    );\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.760343Z","iopub.status.idle":"2025-05-21T17:39:32.760560Z","shell.execute_reply.started":"2025-05-21T17:39:32.760465Z","shell.execute_reply":"2025-05-21T17:39:32.760475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Confmatrix(preds,targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:39:32.761178Z","iopub.status.idle":"2025-05-21T17:39:32.761407Z","shell.execute_reply.started":"2025-05-21T17:39:32.761309Z","shell.execute_reply":"2025-05-21T17:39:32.761318Z"}},"outputs":[],"execution_count":null}]}